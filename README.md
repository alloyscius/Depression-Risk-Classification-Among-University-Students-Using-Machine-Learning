# Depression-Risk-Classification-Among-University-Students-Using-Machine-Learning

This project develops and evaluates machine learning and neural network models to predict depression risk based on demographic, academic, lifestyle, and psychological factors. In addition to performance comparison, the study emphasises **model transparency** by applying **SHAP (SHapley Additive exPlanations)** to explain key risk factors influencing model predictions.

---

## ðŸ“Œ Project Objectives

- Develop a neural network model for predicting depression risk to support social sustainability and mental health well-being
- Assess whether ensemble learning models improve prediction performance
- Enhance model transparency using SHAP to explain influential features contributing to depression risk

---

## ðŸ§  Models Implemented

The following models are trained and evaluated:

### Neural Networks
- **MLP (ReLU activation)**
- **MLP (tanh activation)**
- **MLP (sigmoid activation)**

### Tree-Based Models
- **Random Forest**
- **XGBoost**

### Ensemble Model
- **Stacking Ensemble**
  - Base learners: Random Forest + XGBoost
  - Meta-learner: Logistic Regression

---

```
## ðŸ“‚ Project Structure

â”œâ”€â”€ data/
â”‚ â””â”€â”€ student_depression_dataset_cleaned.csv
â”‚
â”‚ â”œâ”€â”€ 01_preprocessing.ipynb
â”‚ â”œâ”€â”€ 02_model_training_and_evaluation.ipynb
â”‚ â””â”€â”€ 03_shap_explainability.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ mlp_relu_model.joblib
â”‚ â”œâ”€â”€ mlp_tanh_model.joblib
â”‚ â”œâ”€â”€ mlp_sigmoid_model.joblib
â”‚ â”œâ”€â”€ rf_model.joblib
â”‚ â”œâ”€â”€ xgb_model.joblib
â”‚ â””â”€â”€ stacking_model.joblib
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ student_depression_dataset_cleaned.csv

```
---
## ðŸ”— Dataset Source

The dataset used in this project is publicly available on Kaggle:

ðŸ‘‰ **Student Depression Dataset**
https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset

This dataset was downloaded and then preprocessed for this study. All original attributes, data collection authorship, and licensing are preserved as per the source.

---
